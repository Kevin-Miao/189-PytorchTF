{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width = 50 height = 50 align = left src=\"tf.png\">\n",
    "\n",
    "# Introduction to Tensorflow\n",
    "\n",
    "Learning Objectives: *By the end of this assignment, you should be familiar with basic tensor objects and mathematical tensor operations. You should be comfortable with building graphs, debugging common coding errors, and researching Tensorflow documentation for various open-ended tasks.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow** is an open source library for developing and training machine learning models and for high-performance numerical computation. Python scripting suffices for training advanced deep learning models, made possible by Tensorflow developments (tensor-manipulation framework for Python). \n",
    "\n",
    "In 2019, Tensorflow moved from version 1.x to version 2.x, hence many of version 1's APIs are no longer core to the library. To check the default version you're using, import the library and print the version as shown below. Note that this notebook focuses on Tensorflow 2.x! \n",
    "\n",
    "Here are just some of the key abilities of Tensorflow: \n",
    "* efficient execution of low-leve tensor operations on CPU/GPU/TPU\n",
    "* automatic differentiation -- computing gradients of various differentiable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow_version works only in colab\n",
    "try: \n",
    "    %tensorflow_version 2.x\n",
    "except Exception: \n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What are Tensors?\n",
    "\n",
    "**Scalar**: rank 0; contains a single value and no \"axes\" <br>\n",
    "**Vector**: rank 1; like a list of values, with 1 \"axis\" <br>\n",
    "**Matrix**: rank 2; has 2 \"axes\" <br>\n",
    "\n",
    "**Tensor**: a container of data; multi-dimensional \"array(s)\" of same-datatype elements<br>\n",
    "Anything with rank > 2 is a **tensor**.\n",
    "\n",
    "<img width = 700 height = 700 src=\"tensors.png\">\n",
    "\n",
    "Packing a matrix(ices) in an array, the result is a 3D tensor. Then packing a 3D tensor(s) into an array, the result is a 4D tensor, and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constant\n",
    "\n",
    "A **constant** is a tensor that *cannot be modified*. Read through each example below before completing the corresponding **TO DO** exercises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar example\n",
    "rank_0_tensor = tf.constant(256)\n",
    "rank_0_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO *** \n",
    "# 2A) create a constant that holds the value 5\n",
    "five = pass\n",
    "# expect True\n",
    "type(rank_0_tensor) == type(five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector example\n",
    "rank_1_tensor = tf.constant([3, 1, 4])\n",
    "rank_1_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 2B) create a constant that holds a vector with values: 11, 12, 13\n",
    "vec = pass\n",
    "# expect True\n",
    "type(rank_1_tensor) == type(vec)\n",
    "len(rank_1_tensor.shape) == len(vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix example\n",
    "rank_2_tensor = tf.constant([[3, 1, 4], \n",
    "                             [1, 5, 9], \n",
    "                             [2, 6, 5]])\n",
    "rank_2_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO *** \n",
    "# 2C) create a constant that holds a matrix with scalar values all 5\n",
    "mat = pass\n",
    "# expect True\n",
    "type(rank_2_tensor) == type(mat)\n",
    "len(rank_2_tensor.shape) == len(mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rank-3 example\n",
    "rank_3_tensor = tf.constant([[[3, 1, 4, 1, 5],\n",
    "                              [9, 2, 6, 5, 3]],\n",
    "                             [[5, 8, 9, 7, 9],\n",
    "                              [3, 2, 3, 8, 4]],\n",
    "                             [[6, 2, 6, 4, 3],\n",
    "                              [3, 8, 3, 2, 7]]])\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shape**: describes how many dimensions the tensor has along each axis <br>\n",
    "For example, a 3D tensor of shape (3, 3, 5) implies that a single array contains 3 arrays, each of which contain 3 arrays, each of which contain 5 values. \n",
    "Another example, a tensor *train_images* with shape (60000, 28, 28) has 3 axes and the images are greyscale (each scalar has value between 0-255). \n",
    "\n",
    "*Do not get confused between \"dimension\" and \"axis\". Dimension is used to describe the number of values in a particular axis. (ex. a vector with 6 entries is.a 6-dimensional vector of 1 axis)\n",
    "\n",
    "Note that are generally three types of tensors: <br>\n",
    "**Rectangular Tensor**: along each axis, every element is of the same size <br> \n",
    "**Ragged Tensor**: number of elements may vary along each axis <br>\n",
    "**Sparse Tensor**: data is sparse like a wide embedding space  \n",
    "\n",
    "We will only be working with rectangular tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** To DO ***\n",
    "# 2D) can you create a 4D tensor of shape (2, 2, 2, 2)? \n",
    "omg_four_dims = pass\n",
    "# 2E) obtain the shape of omg_five_dims (hint: variable object attribute)\n",
    "shape4 = pass\n",
    "# expect True\n",
    "len(shape4) == 4\n",
    "shape4 == (2, 2, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Variable\n",
    "\n",
    "Variables in Tensorflow represent variable parameter values, especially in machine learning models. During graph computations, variables can be modified by various operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Example\n",
    "var = tf.Variable([[0.0, 3.0], \n",
    "                     [4.0, 1.0]])\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 3A) Constants can be converted into variables. Convert the constant below into a variable. \n",
    "const = tf.Constant([66, 67, 68])\n",
    "to_var = pass\n",
    "\n",
    "# expect True\n",
    "type(var) == type(to_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference the *Assignment, Indexing, Broadcasting, and Shape Manipulation* section [here](https://towardsdatascience.com/mastering-tensorflow-variables-in-5-easy-step-5ba8062a1756). In the exercise below, assign new values to *to_var* without creating a new object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO *** \n",
    "# 3B) Instead of [66, 67, 68], we want [67, 68, 69]\n",
    "to_var. ...\n",
    "\n",
    "# expect True\n",
    "all(to_var.numpy() == np.array([67, 68, 69]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mathematical Operations\n",
    "\n",
    "You can do basic mathematical operations on tensors. Read through the examples prior to the exercise below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.constant([[6, 8], \n",
    "                [7, 9]])\n",
    "n = tf.constant([[4, 7], \n",
    "                [2, 1]])\n",
    "\n",
    "o = tf.constant([[2.0, 3.0], [10.0, 5.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addition example\n",
    "print(tf.add(m, n))\n",
    "print(m + n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplication (element-wise) example\n",
    "print(tf.multiply(m, n))\n",
    "print(m * n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix multiplication example\n",
    "print(tf.matmul(m, n))\n",
    "print(m @ n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find largest value example\n",
    "print(tf.reduce_max(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index of largest value example\n",
    "print(tf.argmax(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 4A) Replace \"pass\" with values such that the all_tens contain all 10s\n",
    "\n",
    "a = tf.constant([[2, 2], \n",
    "                [1, 1]])\n",
    "b = tf.constant([[3, 4], \n",
    "                [2, 1]])\n",
    "\n",
    "c = tf.constant([[pass, pass], [pass, pass]])\n",
    "\n",
    "all_tens = (a @ b) + c\n",
    "print(all_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 4B) Can you interpret the result of argmax for c below? What does [1 2 2] mean? \n",
    "\n",
    "c = tf.constant([[1, 2, 3], [10, 5, 6], [7, 8, 9]])\n",
    "\n",
    "idx = tf.argmax(c)\n",
    "print(idx)\n",
    "\n",
    "# Answer: ___________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 4C) The code below attempts to retrieve the largest scalar, 66, from get_66. What went wrong?\n",
    "\n",
    "get_66 = tf.constant([[5, 7, 22], [43, 66, 18], [4, 4, 4]])\n",
    "\n",
    "# fix the implementation below (NO hardcoding) and feel free to reference documentation \n",
    "arg_max = tf.argmax(get_66)\n",
    "sixty_six = get_66[arg_max]\n",
    "\n",
    "# answer check (expect True)\n",
    "print(sixty_six == 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4D) Can you retrieve the largest scalar values below using the same method from above? \n",
    "# NO hardcoding\n",
    "\n",
    "get_ayyyht = tf.constant([[[8], [0], [1]]])\n",
    "eight = pass\n",
    "# expect True\n",
    "eight == 8\n",
    "\n",
    "get_five = tf.constant([[[[[[5]]]]]])\n",
    "five = pass\n",
    "# expect True\n",
    "five == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Graph \n",
    "\n",
    "Tensorflow uses a dataflow graph, which is a data structure that represents computations as dependencies between various operations. A graph merely defines the operations; it doesn't compute or hold any values. \n",
    "\n",
    "Here is an example of a graph: <img width = 500 height = 500 src=\"graph.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Code Example (represents graph above)\n",
    "\n",
    "# Python function\n",
    "def some_operations(b, w, x): \n",
    "    wx = tf.matmul(w, x)\n",
    "    bwx = tf.add(b, wx)\n",
    "    return tf.nn.relu(bwx)\n",
    "\n",
    "# Create Function object that contains a graph \n",
    "func = tf.function(some_operations)\n",
    "\n",
    "# Create some tensors (note: shape matters!!)\n",
    "a = tf.constant([[5, 10], [4, 2]])\n",
    "b = tf.constant([[1, 3], [6, 2]])\n",
    "c = tf.constant([[12, 61], [4, 2]])\n",
    "\n",
    "# Magic!\n",
    "func(a, b, c).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO *** \n",
    "# 5A) Debugging: the code below attempts to create a softmax graph\n",
    "# First, replace pass with the correct code. Then, run the result and observe the error. \n",
    "# Second, fix the softmax function to address the error. Feel free to reference documentation. \n",
    "\n",
    "import numpy as np\n",
    "# Softmax function: to fix\n",
    "def soft_max(z): \n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=0)\n",
    "\n",
    "# Create Function object that contains a graph\n",
    "soft_func = pass\n",
    "\n",
    "# Generates NotImplementedError -- why? \n",
    "# Answer: ________________________________________\n",
    "soft_func(test_arr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping tensor-using functions in tf.function may not necessarily speed up your code because for small functions, the overhead of calling a graph can dominate the runtime. However, for more complicated computations, graphs can provide significant speedups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Short Exercise\n",
    "\n",
    "Reference Tensorflow 2.0 documentation to complete the exercises below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6A) Create a 2D tensor with shape (2, 3) with values ALL ZERO\n",
    "all_zeros = pass\n",
    "\n",
    "# 6B) Create a 3D tensor with shape (3, 3, 2) with values ALL ONE\n",
    "all_ones = pass\n",
    "\n",
    "# 6C) Reshape all_zeros to shape (1, 6)\n",
    "all_zeroes_reshaped = pass\n",
    "\n",
    "# 6D) Cast all values in all_ones to int32\n",
    "all_ones_int32 = pass\n",
    "\n",
    "# 6E) Create an identity matrix with 3 rows and 3 columns\n",
    "identity_3 = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
