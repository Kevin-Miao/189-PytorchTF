{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Staff Master\n",
    "\n",
    "**Learning Objectives**: The main Learning Objective for this capstone project is to have student learn to become independent with building models. What is the purpose of teaching them CNNs, Transfer Learning and also TF/PyTorch if they can't implement it themselves at the end of the day. \n",
    "\n",
    "**Concrete Goals:**\n",
    "- Student will show all the knowledge they have learned so far.\n",
    "- Student will experiment with project outside of their domain (i.e. healthcare).\n",
    "- Students will learn how to become independent and rely on resources online but also in-class resources.\n",
    "- Students will learn how to work with pickle files.\n",
    "- Students will be made aware of how to make their models more ethical.\n",
    "\n",
    "Obviously, it is not that they are completely starting from scratch since assignments 2A and 2B are practically hand-helding (fill in the blank) assignments where they can refer to at any point.\n",
    "\n",
    "#### Time: Varies per student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow/Keras Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, ELU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/gdrive/My Drive/DS4A_Project/MURA-v1.1/models/cnn'\n",
    "model_path += '{epoch:02d}_{accuracy:.4f}_{val_accuracy:.4f}.hdf5'\n",
    "callbacks = [ModelCheckpoint(model_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 316, 316, 32)      2432      \n",
      "_________________________________________________________________\n",
      "elu (ELU)                    (None, 316, 316, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 158, 158, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 156, 156, 64)      18496     \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 156, 156, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 78, 78, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 76, 76, 64)        36928     \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 76, 76, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 96)        55392     \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 36, 36, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 128)         110720    \n",
      "_________________________________________________________________\n",
      "elu_5 (ELU)                  (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "elu_6 (ELU)                  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "elu_7 (ELU)                  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 635,201\n",
      "Trainable params: 635,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "elu_alpha = 1.8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = 5, input_shape = (320, 320, 3)))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, kernel_size = 3))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, kernel_size = 3))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(96, kernel_size = 3))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(96, kernel_size = 3))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, kernel_size = 3))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(ELU(alpha=elu_alpha))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.00005), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, train_x, train_y, valid_x, valid_y, epochs, callbacks, gen = False): \n",
    "    history = model.fit(train_x, train_y, \n",
    "                        batch_size = 16, \n",
    "                        epochs = epochs, \n",
    "                        callbacks = callbacks, \n",
    "                        validation_data = (valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(h, suptitle, filename): \n",
    "\n",
    "    def plot(train, val, title, y_label, colors): \n",
    "        plt.plot(train, color = colors[0])\n",
    "        plt.plot(val, color = colors[1])\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(y_label)\n",
    "        plt.legend(['train', 'validation'])\n",
    "\n",
    "    acc, val_acc = h.history['accuracy'], h.history['val_accuracy']\n",
    "    loss, val_loss = h.history['loss'], h.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(7, 10))\n",
    "    plt.suptitle(suptitle, fontsize = 18)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plot(acc, val_acc, 'Accuracy vs Epoch#', 'Accuracy', ['skyblue', 'indigo'])\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plot(loss, val_loss, 'Loss vs Epoch#', 'Loss', ['gold', 'crimson'])\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: the data file is too large for GitHub, hence the solution is by default commented out. \n",
    "Student should upload the file themselves and run the code below. \n",
    "\"\"\"\n",
    "# with open('hu_data.pickle', 'rb') as f: \n",
    "#     hu_data = pickle.load(f)\n",
    "# x_train, y_train, x_test, y_test = hu_data\n",
    "# history = fit_model(model, x_train, y_train, x_test, y_test, 70, callbacks)\n",
    "# plot_results(history, 'CNN Metrics', 'cnn_metrics.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Solution\n",
    "\n",
    "One possibe solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "from PIL import Image, ImageStat\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kevinmiao/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "myNet =torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bone(Dataset):\n",
    "    \"\"\"French Fries vs Sushi Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (list of images) : list of images\n",
    "            labels (list of labels) : list of labels\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        #BEGIN SOLUTION 1.3\n",
    "        return len(self.images)\n",
    "        #END SOLUTION 1.3\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "          image = self.transform(image)\n",
    "        label = int(label == 1)\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        return sample\n",
    "bones = Bone(callback['images'], callback['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(np.arange(len(bones)), size=int(len(bones)*0.8), replace=False)\n",
    "test_indices = np.array([x for x in np.arange(len(bones)) if x not in train_indices])\n",
    "train_loader = DataLoader(torch.utils.data.Subset(food_dataset, train_indices), batch_size=8, num_workers=4)\n",
    "test_loader = DataLoader(torch.utils.data.Subset(food_dataset, test_indices), batch_size=8, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mynet().parameters(), lr=alpha, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(myNet(), criterion, optimizer, 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
