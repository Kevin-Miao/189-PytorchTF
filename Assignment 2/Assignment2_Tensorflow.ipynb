{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow for Deep Learning \n",
    "\n",
    "Learning Objectives: <br> *By the end of this assignment, you should be familiar using Keras Sequential and Functional APIs for constructing models. You should be comfortable with debugging common modeling errors and researching Tensorflow documentation for various open-ended tasks.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras** is a deep learning API that runs on top of Tensorflow, with **layers** and **models** as the core data structures. In Tensorflow 2.0, modeling functionalities are under the Keras namespace. (Optional: read about v1 --> v2 API cleanup [here](https://github.com/tensorflow/community/blob/master/rfcs/20180827-api-names.md))\n",
    "\n",
    "Keras provides a clean, approachable interface with abstractions and building blocks for easy prototyping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow_version works only in colab\n",
    "try: \n",
    "    %tensorflow_version 2.x\n",
    "except Exception: \n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# several examples use the mnist dataset -- hence import & split into trian/valid/test sets\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train_full, y_train_full), (x_test,  y_test) = mnist.load_data()\n",
    "x_train, x_valid = x_train_full[12000:] / 255, x_train_full[:12000] / 255\n",
    "y_train, y_valid = y_train_full[12000:], y_train_full[:12000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sequential API \n",
    "\n",
    "The Sequential API allows one to construct the simplest type of model: one with a linear stock of layers -- model with layers created in a step by step fashion. \n",
    "\n",
    "In the examples, we are interested in fashion mnist multi-class classification (ie. models that take 28x28x1 images and classifies each into one of ten classes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# creates a list of layer definitions\n",
    "seq_model = Sequential([ \n",
    "    # flattens 28x28 image to a 1D array \n",
    "    Flatten(input_shape=(28, 28)), \n",
    "    # hidden layer with 256 neurons & relu activation\n",
    "    Dense(256, activation=\"relu\"), \n",
    "    # hidden layer with 128 neurons & relu activation \n",
    "    Dense(128, activation=\"relu\"), \n",
    "    # output layer with 10 neurons & softmax activation \n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# displays model layers (+ layer (type), output shape, param #)\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 TO DO: Sequential Questions \n",
    "You may consult Tensorflow documentation and online sources for any of the questions below. <br>\n",
    "a) Describe the architecture of *seq_model* above. (ie. how many/what types of layers? what is a dense? flatten?) <br>\n",
    "b) What happens if you do not specify an activation function for any one of the dense layers? <br>\n",
    "c) The three dense layers in *seq_model* have 200960, 32896, and 1290 trainable parameters respectively. Based on your knowledge of densely connected neural networks, explain how these numbers are derived.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After model creation, the next step is to call the *compile()* method and specify a loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "                  # loss -- String (name of objective function), objective function, or Loss instance.\n",
    "seq_model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                  # optimizer -- String (name of optimizer) or optimizer instance. \n",
    "                  optimizer = \"sgd\", \n",
    "                  # list of metrics to be evaluated by the model during training and testing.\n",
    "                  # each can be a String (name of built-in function), function, or Metric instance. \n",
    "                  metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train the model by calling the *fit()* function. Notice that calling the *fit()* function returns a *History* object, with its *History.history* attribute recording training loss and metrics values at every epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1707 - accuracy: 0.9519 - val_loss: 0.1733 - val_accuracy: 0.9495\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1541 - accuracy: 0.9561 - val_loss: 0.1608 - val_accuracy: 0.9527\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1393 - accuracy: 0.9609 - val_loss: 0.1514 - val_accuracy: 0.9553\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1273 - accuracy: 0.9638 - val_loss: 0.1375 - val_accuracy: 0.9609\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 982us/step - loss: 0.1165 - accuracy: 0.9671 - val_loss: 0.1308 - val_accuracy: 0.9639\n"
     ]
    }
   ],
   "source": [
    "                            # input data\n",
    "seq_history = seq_model.fit(x = x_train, \n",
    "                            # input labels\n",
    "                            y = y_train, \n",
    "                            # epoch -- an iteration over the entire x and y dataset provided\n",
    "                            epochs = 5, \n",
    "                            # data on which to evaluate the loss and any model metrics at the ennd of each epoch\n",
    "                            validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the Sequential API is easy to use, we cannot create models that share layers, have branches, nor have multiple inputs/outputs. However, we *can* with the Functional API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functional API\n",
    "\n",
    "When constructing models with the Functional API, follow three important steps: <br>\n",
    "1) explicitly define the input layer <br> \n",
    "2) define model layers, connecting each layer using Python functional syntax <br>\n",
    "3) define the model by callling the model object and giving it the input and output layers\n",
    "\n",
    "*func_model* below contains the same architecture as *seq_model*, but uses the Functional API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model \n",
    "\n",
    "# define input tensor\n",
    "input_layer = Input(shape = (28, 28))\n",
    "\n",
    "# stack layers using the syntax: current_layer()(previous_layer)\n",
    "flattened = Flatten()(input_layer)\n",
    "fc1 = Dense(256, activation = \"relu\")(flattened)\n",
    "fc2 = Dense(128, activation = \"relu\")(fc1)\n",
    "predictions = Dense(10, activation = \"softmax\")(fc2)\n",
    "\n",
    "# define model object -- specify input and outputs\n",
    "func_model = Model(inputs = [input_layer], outputs = [predictions])\n",
    "\n",
    "# displays model layers (+ layer (type), output shape, param #)\n",
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the Sequential model, we call the *compile()* method and specify a loss function, optimizer, and metrics. Then, call the *fit()* function and plot metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.6813 - accuracy: 0.8241 - val_loss: 0.3372 - val_accuracy: 0.9069\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3124 - accuracy: 0.9118 - val_loss: 0.2747 - val_accuracy: 0.9234\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2581 - accuracy: 0.9260 - val_loss: 0.2403 - val_accuracy: 0.9327\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2229 - accuracy: 0.9373 - val_loss: 0.2108 - val_accuracy: 0.9398\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1962 - accuracy: 0.9445 - val_loss: 0.1893 - val_accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "func_model.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "                   optimizer = \"sgd\", \n",
    "                   metrics = [\"accuracy\"])\n",
    "\n",
    "func_history = func_model.fit(x_train, \n",
    "                              y_train, \n",
    "                              epochs = 5, \n",
    "                              validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 TO DO: Functional Questions \n",
    "You may consult Tensorflow documentation and online sources for the questions below. <br>\n",
    "a) What is meant by *functional syntax*? <br>\n",
    "b) What are the advantages of using the functional syntax? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 TO DO: Plot Learning Curves\n",
    "Refit any of the two models above, but with epochs = 20. Then evaluate the corresponding metrics in the following cell and plot two graphs: <br>\n",
    "a. train & validation loss for every epoch <br>\n",
    "b. train & validation accuracy for every epoch\n",
    "            \n",
    "You may import any necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "seq_metrics = seq_history.history\n",
    "func_metrics = func_history.history\n",
    "\n",
    "print(type(seq_metrics), type(func_metrics))\n",
    "\n",
    "### your code here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell -- you should see an image of a flower\n",
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "flower = load_sample_image('flower.jpg')\n",
    "    \n",
    "_ = plt.imshow(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell -- dataset of one 100 x 100 x 3 RGB image\n",
    "dataset = np.array([flower], dtype = np.float32)\n",
    "\n",
    "count, height, width, channels = dataset.shape\n",
    "count, height, width, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 1) Convert dataset to tensor object\n",
    "data = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 2) Create a vertical line filter that will be applied using Tensorflow's tf.nn.conv2d function\n",
    "filter_height, filter_width = 10, 10\n",
    "channels_input, channels_output = 3, 1\n",
    "\n",
    "filters = np.zeros(shape = (pass, pass, pass, pass), dtype = np.float32)\n",
    "filters[:, 5:7, :, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 3) create a convolution layer using tf.nn.conv2d and pass in the following arguments: image we are processing, filters, and strides\n",
    "convolution = ...(..., ..., strides = [1, 10, 10, 1], padding = \"SAME\")\n",
    "output = convolution.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell \n",
    "plt.imshow(output[0, :, : 0], cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** To DO *** \n",
    "# 4) Using tf.keras.layers.Conv2D, create a layer with three filters, a 5x5 \n",
    "# visual receptor, and stride of 2\n",
    "convolution = ......(filters = pass, kernel_size = pass, strides = pass, padding = \"SAME\")\n",
    "output = convolution(X).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 5) Plot the first feature map: \n",
    "plt.imshow(output[pass, :, :, pass])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** To DO ***\n",
    "# 6) Plot the second feature map: \n",
    "plt.imshow(output[pass, :, :, pass])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO *** \n",
    "# 7) Plot the third feature map: \n",
    "plt.imshow(ouutput[pass, :, : pass])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO *** \n",
    "# 8) Pass the flower image into the tf.nn.max_pool function below\n",
    "size = [1, 2, 2, 1]\n",
    "maxpool = tf.nn.maxpool(pass, ksize = size, strides = size, padding = \"VALID\")\n",
    "output = maxpool.numpy()\n",
    "plt.imshow(output[0].astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exercise\n",
    "Let's build a model that classifies images into 10 different categories. \n",
    "Requirements: 3 convolution layers, each followed by a maxpooling layer; 2 dense layers at the end; adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers. ...(16, 3, padding='same', activation= pass,\n",
    "                           input_shape=(100, 100, 3)),\n",
    "    tf.keras.layers. ...,\n",
    "    tf.keras.layers. ... (32, 3, padding='same', activation= pass),\n",
    "    tf.keras.layers. ...,\n",
    "    tf.keras.layers. ... (64, 3, padding='same', activation= pass),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers. ... (256, activation= pass),\n",
    "    tf.keras.layers. ... (128, activation= pass)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = pass\n",
    "              loss = pass,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
