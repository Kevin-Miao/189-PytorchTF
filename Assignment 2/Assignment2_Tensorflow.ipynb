{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow for Deep Learning\n",
    "\n",
    "Learning Objectives: <br> *By the end of this assignment, you should be familiar using Keras Sequential and Functional APIs for constructing models. You should be comfortable with debugging common modeling errors and researching Tensorflow documentation for various open-ended tasks.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras** is a deep learning API that runs on top of Tensorflow, with **layers** and **models** as the core data structures. In Tensorflow 2.0, modeling functionalities have been moved under the Keras namespace. (Optional: read about v1 --> v2 API cleanup [here](https://github.com/tensorflow/community/blob/master/rfcs/20180827-api-names.md))\n",
    "\n",
    "Keras provides a clean, approachable interface with abstractions and building blocks for easy prototyping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow_version works only in colab\n",
    "try: \n",
    "    %tensorflow_version 2.x\n",
    "except Exception: \n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mnist dataset is used in various examples, hence imported below\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train_full, y_train_full), (x_test,  y_test) = mnist.load_data()\n",
    "x_train, x_valid = x_train_full[5000:] / 255, x_train_full[:5000] / 255\n",
    "y_train, y_valid = y_train_full[5000:], y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sequential API \n",
    "\n",
    "The Sequential API allows one to construct the simplest type of model: one with a linear stock of layers -- model with layers created in a step by step fashion. \n",
    "\n",
    "The model created below takes 28x28 images as input and classifies each into one of ten categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# creates a list of layer definition\n",
    "seq_model = Sequential([ \n",
    "    # flattens 28x28 image to a 1D array \n",
    "    Flatten(input_shape=(28, 28)), \n",
    "    # hidden layer with 256 neurons & relu activation\n",
    "    Dense(256, activation=\"relu\"), \n",
    "    # hidden layer with 128 neurons & relu activation \n",
    "    Dense(128, activation=\"relu\"), \n",
    "    # output layer with 10 neurons & softmax activation \n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# displays model layers (+ layer (type), output shape, param #)\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 TO DO: Sequential Questions \n",
    "You may consult Tensorflow documentation for the questions below. <br>\n",
    "a) Describe the model architecture of *seq_model* above. (ie. how many/what types of layers? what is a dense? flatten?) <br>\n",
    "b) What happens if you do not specify an activation function for any of the dense layers? <br>\n",
    "c) The three dense layers above have 200960, 32896, and 1290 trainable parameters respectively. How are these numbers derived? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After model creation, the next step is to call the *compile()* method and specify a loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "                  # loss -- String (name of objective function), objective function, or Loss instance.\n",
    "seq_model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                  # optimizer -- String (name of optimizer) or optimizer instance. \n",
    "                  optimizer = \"sgd\", \n",
    "                  # list of metrics to be evaluated by the model during training and testing.\n",
    "                  # each can be a String (name of built-in function), function, or Metric instance. \n",
    "                  metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train the model by calling the *fit()* function. Notice that calling the *fit()* function returns a *History* object, with its *History.history* attribute recording training loss and metrics values at every epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6232 - accuracy: 0.8407 - val_loss: 0.3132 - val_accuracy: 0.9142\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 2s 949us/step - loss: 0.2917 - accuracy: 0.9168 - val_loss: 0.2392 - val_accuracy: 0.9304\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 2s 944us/step - loss: 0.2379 - accuracy: 0.9316 - val_loss: 0.2021 - val_accuracy: 0.9454\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 2s 934us/step - loss: 0.2035 - accuracy: 0.9414 - val_loss: 0.1817 - val_accuracy: 0.9528\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 2s 925us/step - loss: 0.1776 - accuracy: 0.9495 - val_loss: 0.1586 - val_accuracy: 0.9564\n"
     ]
    }
   ],
   "source": [
    "                            # input data\n",
    "seq_history = seq_model.fit(x = x_train, \n",
    "                            # input labels\n",
    "                            y = y_train, \n",
    "                            # epoch -- an iteration over the entire x and y dataset provided\n",
    "                            epochs = 5, \n",
    "                            # data on which to evaluate the loss and any model metrics at the ennd of each epoch\n",
    "                            validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 TO DO: Plot Learning Curves\n",
    "Rerun the cell above, but with epochs = 20. Then evaluate seq_metrics below and plot two graphs: <br>\n",
    "a. train & validation loss over epochs <br>\n",
    "b. train & validation accuracy over epochs \n",
    "            \n",
    "You may import any necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_metrics = seq_history.history\n",
    "\n",
    "### your code here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell -- you should see an image of a flower\n",
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "flower = load_sample_image('flower.jpg')\n",
    "    \n",
    "_ = plt.imshow(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell -- dataset of one 100 x 100 x 3 RGB image\n",
    "dataset = np.array([flower], dtype = np.float32)\n",
    "\n",
    "count, height, width, channels = dataset.shape\n",
    "count, height, width, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 1) Convert dataset to tensor object\n",
    "data = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 2) Create a vertical line filter that will be applied using Tensorflow's tf.nn.conv2d function\n",
    "filter_height, filter_width = 10, 10\n",
    "channels_input, channels_output = 3, 1\n",
    "\n",
    "filters = np.zeros(shape = (pass, pass, pass, pass), dtype = np.float32)\n",
    "filters[:, 5:7, :, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 3) create a convolution layer using tf.nn.conv2d and pass in the following arguments: image we are processing, filters, and strides\n",
    "convolution = ...(..., ..., strides = [1, 10, 10, 1], padding = \"SAME\")\n",
    "output = convolution.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell \n",
    "plt.imshow(output[0, :, : 0], cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** To DO *** \n",
    "# 4) Using tf.keras.layers.Conv2D, create a layer with three filters, a 5x5 \n",
    "# visual receptor, and stride of 2\n",
    "convolution = ......(filters = pass, kernel_size = pass, strides = pass, padding = \"SAME\")\n",
    "output = convolution(X).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***\n",
    "# 5) Plot the first feature map: \n",
    "plt.imshow(output[pass, :, :, pass])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** To DO ***\n",
    "# 6) Plot the second feature map: \n",
    "plt.imshow(output[pass, :, :, pass])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO *** \n",
    "# 7) Plot the third feature map: \n",
    "plt.imshow(ouutput[pass, :, : pass])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO *** \n",
    "# 8) Pass the flower image into the tf.nn.max_pool function below\n",
    "size = [1, 2, 2, 1]\n",
    "maxpool = tf.nn.maxpool(pass, ksize = size, strides = size, padding = \"VALID\")\n",
    "output = maxpool.numpy()\n",
    "plt.imshow(output[0].astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exercise\n",
    "Let's build a model that classifies images into 10 different categories. \n",
    "Requirements: 3 convolution layers, each followed by a maxpooling layer; 2 dense layers at the end; adam optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers. ...(16, 3, padding='same', activation= pass,\n",
    "                           input_shape=(100, 100, 3)),\n",
    "    tf.keras.layers. ...,\n",
    "    tf.keras.layers. ... (32, 3, padding='same', activation= pass),\n",
    "    tf.keras.layers. ...,\n",
    "    tf.keras.layers. ... (64, 3, padding='same', activation= pass),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers. ... (256, activation= pass),\n",
    "    tf.keras.layers. ... (128, activation= pass)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = pass\n",
    "              loss = pass,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
