{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width = 130 height = 130 align = left src=\"tfkeras.jpg\">\n",
    " \n",
    "# Tensorflow for Deep Learning \n",
    "\n",
    "Learning Objectives: *By the end of this assignment, you should be comfortable with using Keras Sequential and Functional APIs for constructing deep learning models. You should be comfortable with debugging common modeling errors and researching Tensorflow documentation for various open-ended tasks.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras** is a deep learning API that runs on top of Tensorflow, with **layers** and **models** as the core data structures. In Tensorflow 2.0, modeling functionalities are organized under the Keras namespace. (Optional: read about v1 --> v2 API cleanup [here](https://github.com/tensorflow/community/blob/master/rfcs/20180827-api-names.md))\n",
    "\n",
    "Keras provides a clean, approachable interface with abstractions and building blocks for easy prototyping and modeling customizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow_version works only in colab\n",
    "try: \n",
    "    %tensorflow_version 2.x\n",
    "except Exception: \n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# several examples use the mnist dataset -- hence import & split into train/valid/test sets\n",
    "\n",
    "\"\"\"\n",
    "Background on Fashion-MNIST Dataset: \n",
    "Fashion-MNIST is a dataset of Zolando's article images, containing 60k training samples and 10k test samples.  \n",
    "Each 28x28 greyscale image belongs to one of ten classes (t-shirt/top, trouser, pullover, dress, coat, sandal, \n",
    "shirt, sneaker, bag, ankle boot). Each pixel-value is an integer between 0 and 255, where higher means darker.\n",
    "\"\"\"\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train_full, y_train_full), (x_test,  y_test) = mnist.load_data()\n",
    "\n",
    "# amount to be in the validation set (80/20 split)\n",
    "split_amt = int(len(x_train_full) * .2)\n",
    "\n",
    "x_train, x_valid = x_train_full[split_amt:] / 255, x_train_full[:split_amt] / 255\n",
    "y_train, y_valid = y_train_full[split_amt:], y_train_full[:split_amt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sequential API \n",
    "\n",
    "The Sequential API allows one to construct the simplest type of model: one with a linear stock of layers -- ie. layers created in a step by step fashion. \n",
    "\n",
    "In the example below, we are interested in constructing a model for 10-class classification with the Fashion-MNIST dataset. Carefully examine the code and associated comments below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# creates a list of layer definitions\n",
    "seq_model = Sequential([ \n",
    "    # flattens 28x28 image to a 1D array \n",
    "    Flatten(input_shape=(28, 28)), \n",
    "    # hidden layer with 256 neurons & relu activation\n",
    "    Dense(256, activation=\"relu\"), \n",
    "    # hidden layer with 128 neurons & relu activation \n",
    "    Dense(128, activation=\"relu\"), \n",
    "    # output layer with 10 neurons & softmax activation \n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# displays model layers (+ layer (type), output shape, param #)\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step following model instantiation is to call the *compile()* method and specify a loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "                  # loss -- String (name of objective function), objective function, or Loss instance.\n",
    "seq_model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                  # optimizer -- String (name of optimizer) or optimizer instance. \n",
    "                  optimizer = \"sgd\", \n",
    "                  # list of metrics to be evaluated by the model during training and testing.\n",
    "                  # each can be a String (name of built-in function), function, or Metric instance. \n",
    "                  metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step following compiling is to train the model by calling the *fit()* method. <br> Doing so returns a *History* object, with its *History.history* attribute holding records of training loss and metrics values at every epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.6485 - accuracy: 0.8314 - val_loss: 0.3383 - val_accuracy: 0.9061\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3071 - accuracy: 0.9118 - val_loss: 0.2684 - val_accuracy: 0.9249\n"
     ]
    }
   ],
   "source": [
    "                            # input data\n",
    "seq_history = seq_model.fit(x = x_train, \n",
    "                            # input labels\n",
    "                            y = y_train, \n",
    "                            # epoch -- an iteration over the entire x and y dataset provided\n",
    "                            epochs = 2, \n",
    "                            # data on which to evaluate the loss and any model metrics at the ennd of each epoch\n",
    "                            validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, fitting the \"best\" model may take a number of iterations -- possibly needing several hyperparameter adjustments! Once complete, the final step is to evaluate the model using the *evaluate()* method on the test set. Recall that the model is evaluated only ONCE on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 859us/step - loss: 35.8529 - accuracy: 0.9200\n",
      "train loss: 35.853\n",
      "train accuracy: 92.000%\n"
     ]
    }
   ],
   "source": [
    "# returns loss value & metrics values for model in test mode (default batchsize is 32)\n",
    "test_loss, test_accuracy = seq_model.evaluate(x_test, y_test)\n",
    "print(f'train loss: {test_loss:.3f}')\n",
    "print(f'train accuracy: {100 * test_accuracy:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the general steps to constructing a model using the Sequential API are: <br> \n",
    "1. Sequential instantiation, with a list of layers\n",
    "2. Compiling the model, indicating the desired loss function, optimizer, and metric(s)\n",
    "3. Fitting the model with the dataset\n",
    "4. Evaluating the model on the test set\n",
    "\n",
    "While the Sequential API is easy to use, we cannot create models that share layers, have branches, nor have multiple inputs/outputs. However, we *can* with the Functional API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO DO: Part 1 Questions\n",
    "You may consult Tensorflow documentation and online sources for any of the questions below. <br>\n",
    "a) Describe the architecture of *seq_model* above. (ie. how many/what types of layers? what is a dense? flatten?) <br>\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "b) What happens if you do not specify an activation function for any one of the dense layers? <br>\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "c) The three dense layers in *seq_model* have 200960, 32896, and 1290 trainable parameters respectively. Based on your knowledge of densely connected neural networks, explain how these numbers are derived. <br> \n",
    "\n",
    "*your answer here*\n",
    "\n",
    "d) Why is the loss function sparse categorical crossentropy? <br>\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "e) What happens if you do not specify a number of epochs in *fit()*? \n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functional API - Pt1\n",
    "\n",
    "*func_model* below contains the same architecture as *seq_model*, but uses the Functional API. Carefully examine the code below and read the comments. Compare it with the Sequential syntax above. What differences and similarities do you notice? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model \n",
    "\n",
    "# define input tensor\n",
    "input_layer = Input(shape = (28, 28))\n",
    "\n",
    "# stack layers using the syntax: current_layer()(previous_layer)\n",
    "flattened = Flatten()(input_layer)\n",
    "fc1 = Dense(256, activation = \"relu\")(flattened)\n",
    "fc2 = Dense(128, activation = \"relu\")(fc1)\n",
    "predictions = Dense(10, activation = \"softmax\")(fc2)\n",
    "\n",
    "# define model object -- specify input and outputs\n",
    "func_model = Model(inputs = [input_layer], outputs = [predictions])\n",
    "\n",
    "# displays model layers (+ layer (type), output shape, param #)\n",
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the Sequential model, we call the *compile()* method and specify a loss function, optimizer, and metrics. Then, call the *fit()* method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0561 - accuracy: 0.9851 - val_loss: 0.0929 - val_accuracy: 0.9719\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0527 - accuracy: 0.9865 - val_loss: 0.0973 - val_accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "func_model.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "                   optimizer = \"sgd\", \n",
    "                   metrics = [\"accuracy\"])\n",
    "\n",
    "func_history = func_model.fit(x_train, \n",
    "                              y_train, \n",
    "                              epochs = 2, \n",
    "                              validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 908us/step - loss: 13.8332 - accuracy: 0.9716\n",
      "train loss: 13.833\n",
      "train accuracy: 97.160%\n"
     ]
    }
   ],
   "source": [
    "# returns loss value & metrics values for model in test mode (default batchsize is 32)\n",
    "test_loss, test_accuracy = func_model.evaluate(x_test, y_test)\n",
    "print(f'train loss: {test_loss:.3f}')\n",
    "print(f'train accuracy: {100 * test_accuracy:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the general steps to constructing a model using the Functional API are: <br>\n",
    "1. explicitly defining the input layer\n",
    "2. defining model layers, connecting each layer using Python functional syntax\n",
    "3. defining the model by calling the model object and giving it the input and output layers\n",
    "4. compiling --> fitting (several iterations) --> evaluating\n",
    "\n",
    "\n",
    "#### TO DO: Part 2 Questions \n",
    "You may consult Tensorflow documentation and online sources for the questions below. <br>\n",
    "a) In the context of modeling, what are the advantage(s) of using the functional syntax? <br>\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "b) Notice that when defining the model object, the parameter names are plural (inputs vs input, outputs vs output). Why is this the case? <br>\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "c) Refit either *seq_model* or *func_model*, but with epochs = 20. <br> Then evaluate the corresponding metrics in the following cell and plot two line graphs: <br>\n",
    "1. train & validation loss for every epoch \n",
    "2. train & validation accuracy for every epoch <br> \n",
    "(You may import any necessary libraries) <br> \n",
    "Based on your graph(s), at how many epochs would you stop training? <br>\n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> <class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' ### your code below ### '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part c -- select one\n",
    "seq_metrics = seq_history.history\n",
    "func_metrics = func_history.history\n",
    "\n",
    "print(type(seq_metrics), type(func_metrics))\n",
    "\n",
    "\"\"\" ### your code below ### \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functional API -- Pt2\n",
    "\n",
    "As hinted, the Functional API allows you to create layers that are impossible with the Sequential API -- ex. parallel layers, splitting, concatenating, etc. We will explore these exclusive functionalities by ...\n",
    "\n",
    "implement a siamese or inception network - let them fill in a base model and final model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling Hacks\n",
    "\n",
    "1. custom loss\n",
    "2. custom activation functions using lambda layers\n",
    "3. callbacks & custom callbacks\n",
    "4. data augmentation \n",
    "\n",
    "-- creating custom loss functions or a class for the function \n",
    "def my_loss_func(y_true, y_pred): pass\n",
    "model.compile(loss = 'my_loss_func'...)\n",
    "\n",
    "-- adding hyperparameters to custom loss functions\n",
    "add wrapper around loss functions with hyperparams as parameters\n",
    "def my_loss_func-wrap(hyperparam): \n",
    "    def my_loss_func ... \n",
    "model.compile(loss = my_loss_func_wrap(hyperparam) ... \n",
    "\n",
    "-- to implement a custom loss as a class -- must import tf.keras.losses import Loss\n",
    "and then let the ccclass inheritfrom Loss\n",
    "ex. class myloss(Loss): \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. exploring documentation exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 ethics of using tensorflow (maybe move this to assignment 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
